# A Paper List for Multimodal Dialogue model

This is a paper list for the multimodal dialogue models.

**Keyword**: *Dialgue model, Multimodal dialogue, Natural Language Processing*

# Paper List

## Dataset

[Visual Dialog](https://arxiv.org/abs/1611.08669), CVPR 2017 [[code]](https://github.com/batra-mlp-lab/visdial)

[OpenViDial: A Large-Scale, Open-Domain Dialogue Dataset with Visual Contexts](https://arxiv.org/abs/2012.15015), Arxiv 2020

[Image-Chat: Engaging Grounded Conversations](https://www.aclweb.org/anthology/2020.acl-main.219/), ACL 2020

[MELD: A Multimodal Multi-Party Dataset for Emotion Recognition in Conversations](https://arxiv.org/abs/1810.02508), ACL 2019 [[code]](http://affective-meld.github.io/)

[CLEVR-Dialog: A Diagnostic Dataset for Multi-Round Reasoning in Visual Dialog](https://www.aclweb.org/anthology/N19-1058), NAACL 2019 [[code]](https://github.com/satwikkottur/clevr-dialog)

[Audio Visual Scene-Aware Dialog](https://ieeexplore.ieee.org/document/8953254), CVPR 2019

[CLEVR-Dialog: A Diagnostic Dataset for Multi-Round Reasoning in Visual Dialog](https://www.aclweb.org/anthology/N19-1058/), NAACL 2019

[Talk the Walk: Navigating New York City through Grounded Dialogue](https://arxiv.org/abs/1807.03367), arXiv 2018

[Game-Based Video-Context Dialogue](https://www.aclweb.org/anthology/D18-1012/), EMNLP 2018

[Towards Building Large Scale Multimodal Domain-Aware Conversation Systems](https://arxiv.org/abs/1704.00200), arXiv 2017 [[code]](https://amritasaha1812.github.io/MMD/)

## Visual QA

[All-in-one  image-grounded  conversa-tional agents](https://arxiv.org/abs/1912.12394), Arxiv 2020

[Two Causal Principles for Improving Visual Dialog](https://arxiv.org/abs/1911.10496), CVPR 2020

[Dialog-based Interactive Image Retrieval](https://arxiv.org/abs/1805.00145), NeurIPS 2018 [[code]](https://github.com/XiaoxiaoGuo/fashion-retrieval)

## Generative Dialogue Model

[Multi-modal open-domain dialogue](https://arxiv.org/abs/2010.01082), arxiv 2020

[The Dialogue Dodecathlon: Open-Domain Knowledge and Image Grounded Conversational Agents](https://www.aclweb.org/anthology/2020.acl-main.222/), ACL2020

[Knowledge-aware multi-modal dialogue systems](http://staff.ustc.edu.cn/~hexn/papers/mm18-multimodal-dialog.pdf), MM 2018

[Image-Grounded Conversations: Multimodal Context for Natural Question and Response Generation](https://www.aclweb.org/anthology/I17-1047/), IJCNLP 2017

## Language Grounding in Vision

[Visual Coreference Resolution in Visual Dialog using Neural Module Networks](https://arxiv.org/abs/1809.01816), ECCV 2018 [[code]](https://github.com/facebookresearch/corefnmn)

[Vision-and-Dialog Navigation](https://arxiv.org/abs/1907.04957), arXiv 2019 [[code]](https://github.com/mmurray/cvdn)

## Multimodal RL

[Multimodal Hierarchical Reinforcement Learning Policy for Task-Oriented Visual Dialog](https://arxiv.org/abs/1805.03257), SIGDIAL 2018


## Survey

[Trends in Integration of Vision and Language Research: A Survey of Tasks, Datasets, and Methods](https://arxiv.org/abs/1907.09358), JAIR 2020

## Social Media Related

[Multimodal dialogue on social media](https://www.tandfonline.com/doi/full/10.1080/10350330.2018.1504732), Social Semiotics 2018

**Welcome to open issues or make pull requests!**
